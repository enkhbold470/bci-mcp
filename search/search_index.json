{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Brain-Computer Interface with Model Context Protocol","text":"<p>Welcome to the documentation for BCI-MCP, an integration of Brain-Computer Interface (BCI) technology with the Model Context Protocol (MCP) for advanced neural signal acquisition, processing, and AI-enabled interactions.</p>"},{"location":"#overview","title":"Overview","text":"<p>BCI-MCP combines the power of:</p> <ul> <li>Brain-Computer Interface (BCI): Real-time acquisition and processing of neural signals</li> <li>Model Context Protocol (MCP): Standardized AI communication interface </li> </ul> <p>This integration enables a wide range of advanced applications in healthcare, accessibility, research, and human-computer interaction.</p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#bci-core-features","title":"BCI Core Features","text":"<ul> <li>Neural Signal Acquisition: Capture electrical signals from brain activity in real-time</li> <li>Signal Processing: Preprocess, extract features, and classify brain signals</li> <li>Command Generation: Convert interpreted brain signals into commands</li> <li>Feedback Mechanisms: Provide feedback to help users improve control</li> <li>Real-time Operation: Process brain activity with minimal delay</li> </ul>"},{"location":"#mcp-integration-features","title":"MCP Integration Features","text":"<ul> <li>Standardized Context Sharing: Connect BCI data with AI models using MCP</li> <li>Tool Exposure: Make BCI functions available to AI applications</li> <li>Composable Workflows: Build complex operations combining BCI signals and AI processing</li> <li>Secure Data Exchange: Enable privacy-preserving neural data transmission</li> </ul>"},{"location":"#advanced-applications","title":"Advanced Applications","text":"<p>The BCI-MCP integration enables a range of cutting-edge applications:</p>"},{"location":"#healthcare-and-accessibility","title":"Healthcare and Accessibility","text":"<ul> <li>Assistive Technology: Enable individuals with mobility impairments to control devices</li> <li>Rehabilitation: Support neurological rehabilitation with real-time feedback</li> <li>Diagnostic Tools: Aid in diagnosing neurological conditions</li> </ul>"},{"location":"#research-and-development","title":"Research and Development","text":"<ul> <li>Neuroscience Research: Facilitate studies of brain function and cognition</li> <li>BCI Training: Accelerate learning and adaptation to BCI control</li> <li>Protocol Development: Establish standards for neural data exchange</li> </ul>"},{"location":"#ai-enhanced-interfaces","title":"AI-Enhanced Interfaces","text":"<ul> <li>Adaptive Interfaces: Interfaces that adjust based on neural signals and AI assistance</li> <li>Intent Recognition: Better understanding of user intent through neural signals</li> <li>Augmentative Communication: Enhanced communication for individuals with speech disabilities</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To start using BCI-MCP, check out our Quick Start Guide.</p>"},{"location":"#architecture","title":"Architecture","text":"<p>The BCI-MCP system consists of several key components:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 \u2502      \u2502                 \u2502      \u2502                 \u2502\n\u2502  BCI Hardware   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2502  BCI Software   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2502   MCP Server    \u2502\n\u2502                 \u2502      \u2502                 \u2502      \u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                           \u2502\n                                                           \u2502\n                                                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                                  \u2502                 \u2502\n                                                  \u2502  AI Applications \u2502\n                                                  \u2502                 \u2502\n                                                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"#documentation-status","title":"Documentation Status","text":"<p>This documentation is automatically built and deployed using GitHub Actions when changes are made to the main branch.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions from the community! Check out our Contributing Guide to learn how you can help.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file in the repository for details.</p>"},{"location":"#new-update-2025-03-23","title":"New Update (2025-03-23)","text":"<p>This is a test update to trigger the documentation workflow. The documentation should be automatically deployed to GitHub Pages.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Initial documentation structure</li> <li>GitHub Pages deployment workflow</li> <li>Basic project structure and dependencies</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Updated GitHub Pages workflow to use the latest GitHub Actions</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Fixed deprecated artifact actions in GitHub workflow</li> </ul>"},{"location":"changelog/#010-2023-03-23","title":"0.1.0 - 2023-03-23","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Initial repository setup</li> <li>Basic BCI device interface</li> <li>Simple MCP client implementation</li> <li>Project documentation</li> <li>Docker configuration</li> <li>Signal processing utilities</li> <li>Bandpass filter implementation</li> <li>Power spectral density analysis</li> <li>Time-domain feature extraction</li> <li>Example scripts for device connection</li> <li>Configuration system</li> </ul>"},{"location":"contributing/","title":"Contributing to BCI-MCP","text":"<p>Thank you for your interest in contributing to the Brain-Computer Interface Model Context Protocol (BCI-MCP) project! This document outlines the process for contributing to the project and provides guidelines to help make the contribution process smooth for everyone.</p>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>This project adheres to a Code of Conduct that all contributors are expected to follow. By participating, you are expected to uphold this code. Please report unacceptable behavior to the project maintainers.</p>"},{"location":"contributing/#how-can-i-contribute","title":"How Can I Contribute?","text":""},{"location":"contributing/#reporting-bugs","title":"Reporting Bugs","text":"<p>If you find a bug in the codebase, please submit an issue using the bug report template. Before creating a bug report, please check that it hasn't already been reported. In your report, include:</p> <ul> <li>A clear, descriptive title</li> <li>Steps to reproduce the issue</li> <li>Expected behavior and actual behavior</li> <li>Any relevant logs or error messages</li> <li>Environment details (OS, Python version, etc.)</li> </ul>"},{"location":"contributing/#suggesting-enhancements","title":"Suggesting Enhancements","text":"<p>We welcome suggestions for new features or improvements. Please submit an issue using the feature request template, including:</p> <ul> <li>A clear description of the enhancement</li> <li>The motivation behind it</li> <li>Any alternatives you've considered</li> <li>If applicable, a sketch or mockup of the enhancement</li> </ul>"},{"location":"contributing/#pull-requests","title":"Pull Requests","text":"<p>We actively welcome pull requests:</p> <ol> <li>Fork the repository and create a branch from <code>main</code></li> <li>If you've added code, add tests that cover your changes</li> <li>Ensure your code passes all tests</li> <li>Update any relevant documentation</li> <li>Submit a pull request</li> </ol>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/enkhbold470/bci-mcp.git\ncd bci-mcp\n</code></pre></p> </li> <li> <p>Create and activate a virtual environment:    <pre><code>python -m venv venv\n# On Windows\nvenv\\Scripts\\activate\n# On macOS/Linux\nsource venv/bin/activate\n</code></pre></p> </li> <li> <p>Install development dependencies:    <pre><code>pip install -r requirements.txt\npip install -r requirements-dev.txt\n</code></pre></p> </li> <li> <p>Set up pre-commit hooks:    <pre><code>pre-commit install\n</code></pre></p> </li> </ol>"},{"location":"contributing/#coding-guidelines","title":"Coding Guidelines","text":""},{"location":"contributing/#python-style-guide","title":"Python Style Guide","text":"<p>We follow the PEP 8 style guide for Python code. Some key points:</p> <ul> <li>Use 4 spaces for indentation (not tabs)</li> <li>Use snake_case for variable and function names</li> <li>Use CamelCase for class names</li> <li>Maximum line length of 88 characters (following Black formatting)</li> <li>Add docstrings for all functions, classes, and modules</li> </ul>"},{"location":"contributing/#documentation","title":"Documentation","text":"<ul> <li>Use Google-style docstrings for Python code</li> <li>Update the documentation when adding or modifying features</li> <li>For the MkDocs site, follow the existing format and structure</li> </ul>"},{"location":"contributing/#testing","title":"Testing","text":"<ul> <li>Write unit tests for all new functionality</li> <li>Make sure all tests pass before submitting a pull request</li> <li>Aim for high test coverage of your code</li> </ul> <p>Run tests with: <pre><code>pytest\n</code></pre></p>"},{"location":"contributing/#git-workflow","title":"Git Workflow","text":"<ol> <li> <p>Create a new branch for each feature or bugfix:    <pre><code>git checkout -b feature/your-feature-name\n# or\ngit checkout -b fix/your-bugfix-name\n</code></pre></p> </li> <li> <p>Make frequent, small commits with clear messages:    <pre><code>git commit -m \"Add clear description of the changes made\"\n</code></pre></p> </li> <li> <p>Push your branch to your fork:    <pre><code>git push origin feature/your-feature-name\n</code></pre></p> </li> <li> <p>Create a pull request to the <code>main</code> branch of the original repository</p> </li> </ol>"},{"location":"contributing/#release-process","title":"Release Process","text":"<p>The project follows Semantic Versioning:</p> <ul> <li>MAJOR version for incompatible API changes</li> <li>MINOR version for backward-compatible functionality additions</li> <li>PATCH version for backward-compatible bug fixes</li> </ul>"},{"location":"contributing/#communication","title":"Communication","text":"<ul> <li>Submit issues for bug reports and feature requests</li> <li>Join the discussion in the issue tracker</li> <li>Contact the maintainers directly for security issues or CoC violations</li> </ul>"},{"location":"contributing/#attribution","title":"Attribution","text":"<p>This contribution guide is adapted from the Atom Contributing Guide and the Contributor Covenant.</p> <p>Thank you for contributing to BCI-MCP! </p>"},{"location":"test/","title":"Test Page","text":"<p>This is a test file to trigger the GitHub Pages workflow.</p>"},{"location":"test/#testing-mkdocs-deployment","title":"Testing MkDocs Deployment","text":"<p>When this file is added, it should trigger the GitHub Pages workflow, which will build the MkDocs site and deploy it to GitHub Pages.</p> <p>The site should be available at: https://enkhbold470.github.io/bci-mcp/</p>"},{"location":"test/#features-to-test","title":"Features to Test","text":"<ul> <li>Navigation</li> <li>Theme</li> <li>Links</li> <li>Code blocks</li> </ul> <pre><code># Example code block\ndef hello_world():\n    print(\"Hello, BCI-MCP!\")\n</code></pre>"},{"location":"api/bci-module/","title":"BCI Module API Reference","text":"<p>This document provides a comprehensive reference for the Brain-Computer Interface (BCI) module API.</p>"},{"location":"api/bci-module/#core-classes","title":"Core Classes","text":""},{"location":"api/bci-module/#bcidevice","title":"<code>BciDevice</code>","text":"<p>Base class for all BCI devices.</p> <pre><code>class BciDevice:\n    def __init__(self, config):\n        \"\"\"\n        Initialize a BCI device.\n\n        Args:\n            config (dict): Configuration parameters for the device\n        \"\"\"\n        pass\n\n    def connect(self):\n        \"\"\"\n        Connect to the BCI device.\n\n        Returns:\n            bool: True if connection successful, False otherwise\n        \"\"\"\n        pass\n\n    def disconnect(self):\n        \"\"\"\n        Disconnect from the BCI device.\n\n        Returns:\n            bool: True if disconnection successful, False otherwise\n        \"\"\"\n        pass\n\n    def start_stream(self):\n        \"\"\"\n        Start data streaming from the device.\n\n        Returns:\n            bool: True if streaming started successfully, False otherwise\n        \"\"\"\n        pass\n\n    def stop_stream(self):\n        \"\"\"\n        Stop data streaming from the device.\n\n        Returns:\n            bool: True if streaming stopped successfully, False otherwise\n        \"\"\"\n        pass\n\n    def get_data(self, samples=None):\n        \"\"\"\n        Get data from the device buffer.\n\n        Args:\n            samples (int, optional): Number of samples to retrieve\n\n        Returns:\n            numpy.ndarray: Array of samples with shape (samples, channels)\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/bci-module/#openbcidevice","title":"<code>OpenBciDevice</code>","text":"<p>Implementation of <code>BciDevice</code> for OpenBCI hardware.</p> <pre><code>class OpenBciDevice(BciDevice):\n    def __init__(self, port, baud=115200, board_type=\"cyton\"):\n        \"\"\"\n        Initialize an OpenBCI device.\n\n        Args:\n            port (str): Serial port for the device\n            baud (int): Baud rate for serial communication\n            board_type (str): Type of OpenBCI board ('cyton', 'ganglion', or 'daisy')\n        \"\"\"\n        pass\n\n    # Additional OpenBCI-specific methods\n    def set_channel_settings(self, channel, setting):\n        \"\"\"\n        Configure settings for a specific channel.\n\n        Args:\n            channel (int): Channel number (1-based)\n            setting (str): Setting command\n\n        Returns:\n            bool: True if setting was applied successfully, False otherwise\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/bci-module/#emotivdevice","title":"<code>EmotivDevice</code>","text":"<p>Implementation of <code>BciDevice</code> for Emotiv hardware.</p> <pre><code>class EmotivDevice(BciDevice):\n    def __init__(self, client_id, client_secret, profile=None):\n        \"\"\"\n        Initialize an Emotiv device.\n\n        Args:\n            client_id (str): Emotiv API client ID\n            client_secret (str): Emotiv API client secret\n            profile (str, optional): User profile name\n        \"\"\"\n        pass\n\n    # Additional Emotiv-specific methods\n    def get_contact_quality(self):\n        \"\"\"\n        Get the contact quality for each electrode.\n\n        Returns:\n            dict: Dictionary mapping electrode names to quality values\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/bci-module/#utility-functions","title":"Utility Functions","text":""},{"location":"api/bci-module/#data-handling","title":"Data Handling","text":"<pre><code>def save_recording(data, filename, metadata=None):\n    \"\"\"\n    Save recorded BCI data to a file.\n\n    Args:\n        data (numpy.ndarray): Data array with shape (samples, channels)\n        filename (str): Output file name\n        metadata (dict, optional): Additional metadata to save\n\n    Returns:\n        bool: True if save was successful, False otherwise\n    \"\"\"\n    pass\n\ndef load_recording(filename):\n    \"\"\"\n    Load recorded BCI data from a file.\n\n    Args:\n        filename (str): Input file name\n\n    Returns:\n        tuple: (data, metadata) where data is a numpy.ndarray\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/bci-module/#device-discovery","title":"Device Discovery","text":"<pre><code>def list_available_devices():\n    \"\"\"\n    List all available BCI devices connected to the system.\n\n    Returns:\n        list: List of dictionaries with device information\n    \"\"\"\n    pass\n\ndef auto_detect_device():\n    \"\"\"\n    Automatically detect and connect to a BCI device.\n\n    Returns:\n        BciDevice: Connected device instance or None if no device found\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/bci-module/#events-and-markers","title":"Events and Markers","text":"<pre><code>class MarkerHandler:\n    def __init__(self, device):\n        \"\"\"\n        Initialize a marker handler for event annotation.\n\n        Args:\n            device (BciDevice): The BCI device to attach to\n        \"\"\"\n        pass\n\n    def add_marker(self, marker_code, timestamp=None, description=None):\n        \"\"\"\n        Add a marker to the data stream.\n\n        Args:\n            marker_code (int): Numeric code for the marker\n            timestamp (float, optional): Custom timestamp (uses current time if None)\n            description (str, optional): Text description of the marker\n\n        Returns:\n            bool: True if marker was added successfully, False otherwise\n        \"\"\"\n        pass\n\n    def get_markers(self, start_time=None, end_time=None):\n        \"\"\"\n        Get markers within a time range.\n\n        Args:\n            start_time (float, optional): Start time for marker retrieval\n            end_time (float, optional): End time for marker retrieval\n\n        Returns:\n            list: List of markers with timestamps and codes\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/bci-module/#exception-classes","title":"Exception Classes","text":"<pre><code>class BciError(Exception):\n    \"\"\"Base exception class for all BCI-related errors.\"\"\"\n    pass\n\nclass ConnectionError(BciError):\n    \"\"\"Exception raised when connection to a BCI device fails.\"\"\"\n    pass\n\nclass StreamError(BciError):\n    \"\"\"Exception raised when there is an error with the data stream.\"\"\"\n    pass\n\nclass ConfigurationError(BciError):\n    \"\"\"Exception raised when there is an error in the device configuration.\"\"\"\n    pass\n</code></pre>"},{"location":"api/bci-module/#usage-examples","title":"Usage Examples","text":"<pre><code># Example 1: Basic usage with OpenBCI\nfrom src.bci import OpenBciDevice\n\n# Initialize the device\ndevice = OpenBciDevice(port=\"/dev/ttyUSB0\", board_type=\"cyton\")\n\n# Connect and start streaming\nif device.connect():\n    device.start_stream()\n\n    # Get 1000 samples of data\n    data = device.get_data(samples=1000)\n\n    # Process the data\n    # ...\n\n    # Stop streaming and disconnect\n    device.stop_stream()\n    device.disconnect()\n\n# Example 2: Using markers for event-related analysis\nfrom src.bci import OpenBciDevice, MarkerHandler\n\ndevice = OpenBciDevice(port=\"/dev/ttyUSB0\")\ndevice.connect()\ndevice.start_stream()\n\n# Create a marker handler\nmarkers = MarkerHandler(device)\n\n# Add markers during an experiment\nmarkers.add_marker(1, description=\"Stimulus onset\")\n# ... run experiment ...\nmarkers.add_marker(2, description=\"Response\")\n\n# Get data with markers\ndata = device.get_data()\nall_markers = markers.get_markers()\n\n# Clean up\ndevice.stop_stream()\ndevice.disconnect()\n</code></pre>"},{"location":"api/bci-module/#next-steps","title":"Next Steps","text":"<p>For integration with the Model Context Protocol, see the MCP Module API documentation. </p>"},{"location":"api/mcp-module/","title":"MCP Module API Reference","text":"<p>This document provides a comprehensive reference for the Model Context Protocol (MCP) module API, which facilitates the integration of brain-computer interface data with large language models.</p>"},{"location":"api/mcp-module/#core-classes","title":"Core Classes","text":""},{"location":"api/mcp-module/#mcpclient","title":"<code>McpClient</code>","text":"<p>The main client class for interacting with the Model Context Protocol.</p> <pre><code>class McpClient:\n    def __init__(self, api_key=None, api_endpoint=None, model=\"default\"):\n        \"\"\"\n        Initialize an MCP client.\n\n        Args:\n            api_key (str, optional): API key for authentication\n            api_endpoint (str, optional): Custom API endpoint URL\n            model (str): Model identifier to use\n        \"\"\"\n        pass\n\n    def query(self, prompt, context=None, options=None):\n        \"\"\"\n        Send a query to the MCP API.\n\n        Args:\n            prompt (str): The main prompt text\n            context (dict, optional): Additional context data, including BCI data\n            options (dict, optional): Query options like temperature, max_tokens, etc.\n\n        Returns:\n            McpResponse: Response object containing the model's output\n        \"\"\"\n        pass\n\n    def streaming_query(self, prompt, context=None, options=None, callback=None):\n        \"\"\"\n        Send a streaming query to the MCP API.\n\n        Args:\n            prompt (str): The main prompt text\n            context (dict, optional): Additional context data, including BCI data\n            options (dict, optional): Query options like temperature, max_tokens, etc.\n            callback (callable, optional): Function to call with each chunk of the response\n\n        Returns:\n            Generator[str]: Generator yielding response chunks\n        \"\"\"\n        pass\n\n    def feedback(self, session_id, feedback_data):\n        \"\"\"\n        Send feedback about a previous response.\n\n        Args:\n            session_id (str): Session ID from a previous query\n            feedback_data (dict): Feedback information\n\n        Returns:\n            bool: True if feedback was successfully submitted\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/mcp-module/#mcpresponse","title":"<code>McpResponse</code>","text":"<p>Class representing a response from the MCP API.</p> <pre><code>class McpResponse:\n    def __init__(self, response_data):\n        \"\"\"\n        Initialize an MCP response.\n\n        Args:\n            response_data (dict): Raw response data from the API\n        \"\"\"\n        pass\n\n    @property\n    def text(self):\n        \"\"\"\n        Get the text content of the response.\n\n        Returns:\n            str: Response text\n        \"\"\"\n        pass\n\n    @property\n    def session_id(self):\n        \"\"\"\n        Get the session ID for this response.\n\n        Returns:\n            str: Session ID for tracking and feedback\n        \"\"\"\n        pass\n\n    @property\n    def usage(self):\n        \"\"\"\n        Get usage information for this response.\n\n        Returns:\n            dict: Token usage information\n        \"\"\"\n        pass\n\n    @property\n    def metadata(self):\n        \"\"\"\n        Get additional metadata from the response.\n\n        Returns:\n            dict: Response metadata\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/mcp-module/#bcicontextprocessor","title":"<code>BciContextProcessor</code>","text":"<p>Class for processing BCI data into a format suitable for the MCP.</p> <pre><code>class BciContextProcessor:\n    def __init__(self, features=None):\n        \"\"\"\n        Initialize a BCI context processor.\n\n        Args:\n            features (list, optional): List of feature extractors to use\n        \"\"\"\n        pass\n\n    def process(self, bci_data):\n        \"\"\"\n        Process raw BCI data into a context format.\n\n        Args:\n            bci_data (numpy.ndarray): Raw BCI data\n\n        Returns:\n            dict: Processed context data\n        \"\"\"\n        pass\n\n    def add_feature_extractor(self, extractor):\n        \"\"\"\n        Add a feature extractor to the processor.\n\n        Args:\n            extractor (FeatureExtractor): Feature extractor instance\n\n        Returns:\n            self: For method chaining\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/mcp-module/#feature-extractors","title":"Feature Extractors","text":"<pre><code>class FeatureExtractor:\n    \"\"\"Base class for all feature extractors.\"\"\"\n\n    def extract(self, data):\n        \"\"\"\n        Extract features from BCI data.\n\n        Args:\n            data (numpy.ndarray): BCI data\n\n        Returns:\n            dict: Extracted features\n        \"\"\"\n        pass\n\nclass PowerBandExtractor(FeatureExtractor):\n    \"\"\"Extract power in specific frequency bands.\"\"\"\n\n    def __init__(self, bands=None, sampling_rate=250):\n        \"\"\"\n        Initialize a power band extractor.\n\n        Args:\n            bands (dict, optional): Dictionary of frequency bands\n            sampling_rate (int): Sampling rate of the data in Hz\n        \"\"\"\n        pass\n\nclass ConnectivityExtractor(FeatureExtractor):\n    \"\"\"Extract connectivity metrics between channels.\"\"\"\n\n    def __init__(self, method=\"coherence\"):\n        \"\"\"\n        Initialize a connectivity extractor.\n\n        Args:\n            method (str): Connectivity method to use\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/mcp-module/#utility-functions","title":"Utility Functions","text":""},{"location":"api/mcp-module/#authentication","title":"Authentication","text":"<pre><code>def load_api_key(key_file=None):\n    \"\"\"\n    Load an API key from a file or environment variable.\n\n    Args:\n        key_file (str, optional): Path to a file containing the API key\n\n    Returns:\n        str: The API key\n    \"\"\"\n    pass\n\ndef generate_auth_header(api_key):\n    \"\"\"\n    Generate an authentication header for API requests.\n\n    Args:\n        api_key (str): API key\n\n    Returns:\n        dict: Authentication header\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/mcp-module/#context-management","title":"Context Management","text":"<pre><code>def merge_contexts(contexts):\n    \"\"\"\n    Merge multiple context dictionaries.\n\n    Args:\n        contexts (list): List of context dictionaries\n\n    Returns:\n        dict: Merged context\n    \"\"\"\n    pass\n\ndef compress_context(context, max_size=None):\n    \"\"\"\n    Compress a context to reduce its size.\n\n    Args:\n        context (dict): Context to compress\n        max_size (int, optional): Maximum size in bytes\n\n    Returns:\n        dict: Compressed context\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/mcp-module/#exception-classes","title":"Exception Classes","text":"<pre><code>class McpError(Exception):\n    \"\"\"Base exception class for all MCP-related errors.\"\"\"\n    pass\n\nclass ApiConnectionError(McpError):\n    \"\"\"Exception raised when connection to the MCP API fails.\"\"\"\n    pass\n\nclass AuthenticationError(McpError):\n    \"\"\"Exception raised when authentication fails.\"\"\"\n    pass\n\nclass QueryError(McpError):\n    \"\"\"Exception raised when there's an error processing a query.\"\"\"\n    pass\n\nclass ContextProcessingError(McpError):\n    \"\"\"Exception raised when there's an error processing context data.\"\"\"\n    pass\n</code></pre>"},{"location":"api/mcp-module/#usage-examples","title":"Usage Examples","text":"<pre><code># Example 1: Basic query with BCI data\nfrom src.mcp import McpClient\nfrom src.bci import OpenBciDevice\nfrom src.mcp.context import BciContextProcessor\n\n# Initialize BCI device and client\ndevice = OpenBciDevice(port=\"/dev/ttyUSB0\")\nclient = McpClient(api_key=\"your_api_key\")\nprocessor = BciContextProcessor()\n\n# Collect and process BCI data\ndevice.connect()\ndevice.start_stream()\nbci_data = device.get_data(samples=500)\ncontext = processor.process(bci_data)\n\n# Send query with BCI context\nresponse = client.query(\n    prompt=\"What can you infer about my cognitive state?\",\n    context=context\n)\n\nprint(response.text)\n\n# Example 2: Streaming response with feedback\ndef handle_chunk(chunk):\n    print(chunk, end=\"\", flush=True)\n\nresponse = client.streaming_query(\n    prompt=\"Generate a meditation based on my current state.\",\n    context=context,\n    callback=handle_chunk\n)\n\n# Send feedback about the response\nclient.feedback(\n    session_id=response.session_id,\n    feedback_data={\"rating\": 4, \"comments\": \"Very helpful meditation\"}\n)\n</code></pre>"},{"location":"api/mcp-module/#integrating-with-the-bci-module","title":"Integrating with the BCI Module","text":"<p>The MCP module is designed to work closely with the BCI module. Typically, you would:</p> <ol> <li>Collect data from a BCI device</li> <li>Process the data using signal processing tools</li> <li>Convert the processed data into a context format</li> <li>Send the context along with a prompt to the MCP API</li> <li>Process and use the response</li> </ol> <p>For more information on collecting BCI data, see the BCI Module API documentation. </p>"},{"location":"features/bci-features/","title":"BCI Features","text":"<p>This document outlines the key features of the Brain-Computer Interface (BCI) component of the BCI-MCP system.</p>"},{"location":"features/bci-features/#supported-devices","title":"Supported Devices","text":"<p>The BCI-MCP system is designed to work with a variety of BCI hardware devices, including:</p>"},{"location":"features/bci-features/#openbci","title":"OpenBCI","text":"<ul> <li>Cyton Board: 8-channel EEG acquisition</li> <li>Ganglion Board: 4-channel EEG acquisition</li> <li>Cyton + Daisy: 16-channel EEG acquisition</li> <li>WiFi Shield: Wireless data transmission</li> </ul>"},{"location":"features/bci-features/#emotiv","title":"Emotiv","text":"<ul> <li>EPOC+: 14-channel EEG headset</li> <li>EPOC Flex: Advanced EEG acquisition with flexible positioning</li> <li>Insight: 5-channel mobile EEG headset</li> </ul>"},{"location":"features/bci-features/#neurosky","title":"NeuroSky","text":"<ul> <li>MindWave: Single-channel EEG headset</li> </ul>"},{"location":"features/bci-features/#custom-hardware","title":"Custom Hardware","text":"<ul> <li>Support for custom and DIY EEG hardware through configurable device interfaces</li> </ul>"},{"location":"features/bci-features/#data-acquisition","title":"Data Acquisition","text":""},{"location":"features/bci-features/#sampling-capabilities","title":"Sampling Capabilities","text":"<ul> <li>Adjustable sampling rates (up to 1000 Hz depending on hardware)</li> <li>Multi-channel data acquisition</li> <li>Real-time impedance checking</li> <li>Signal quality monitoring</li> </ul>"},{"location":"features/bci-features/#data-formats","title":"Data Formats","text":"<ul> <li>Standard EDF/EDF+ format support</li> <li>CSV export functionality</li> <li>Integration with common EEG data formats</li> <li>Raw data access for custom processing</li> </ul>"},{"location":"features/bci-features/#eeg-monitoring","title":"EEG Monitoring","text":""},{"location":"features/bci-features/#real-time-visualization","title":"Real-time Visualization","text":"<ul> <li>Time-domain signal plotting</li> <li>Frequency spectrum analysis</li> <li>Topographical mapping</li> <li>Custom visualization components</li> </ul>"},{"location":"features/bci-features/#impedance-testing","title":"Impedance Testing","text":"<ul> <li>Real-time electrode impedance monitoring</li> <li>Visual feedback for connection quality</li> <li>Electrode status indicators</li> </ul>"},{"location":"features/bci-features/#supported-paradigms","title":"Supported Paradigms","text":""},{"location":"features/bci-features/#p300","title":"P300","text":"<ul> <li>Oddball paradigm implementation</li> <li>P300 speller matrix</li> <li>Target detection</li> </ul>"},{"location":"features/bci-features/#steady-state-visual-evoked-potentials-ssvep","title":"Steady-State Visual Evoked Potentials (SSVEP)","text":"<ul> <li>Frequency-coded stimulation</li> <li>Phase-coded stimulation</li> <li>Multi-target detection</li> </ul>"},{"location":"features/bci-features/#motor-imagery","title":"Motor Imagery","text":"<ul> <li>Left/right hand imagery</li> <li>Multiple body part classification</li> <li>Continuous control paradigms</li> </ul>"},{"location":"features/bci-features/#passive-bci","title":"Passive BCI","text":"<ul> <li>Cognitive workload monitoring</li> <li>Attention level tracking</li> <li>Emotional state detection</li> </ul>"},{"location":"features/bci-features/#markers-and-events","title":"Markers and Events","text":""},{"location":"features/bci-features/#event-annotation","title":"Event Annotation","text":"<ul> <li>Precise timestamp synchronization</li> <li>Custom event markers</li> <li>Experimental protocol design tools</li> </ul>"},{"location":"features/bci-features/#trigger-io","title":"Trigger I/O","text":"<ul> <li>External trigger input/output</li> <li>Hardware synchronization</li> <li>Integration with stimulus presentation software</li> </ul>"},{"location":"features/bci-features/#extension-capabilities","title":"Extension Capabilities","text":""},{"location":"features/bci-features/#plugin-architecture","title":"Plugin Architecture","text":"<ul> <li>Custom signal processing plugin support</li> <li>Protocol extension framework</li> <li>Device driver extensibility</li> </ul>"},{"location":"features/bci-features/#api-access","title":"API Access","text":"<ul> <li>Comprehensive Python API</li> <li>WebSocket streaming for web applications</li> <li>Network data transmission</li> </ul>"},{"location":"features/bci-features/#example-usage","title":"Example Usage","text":"<pre><code>from bci_mcp.devices import OpenBciDevice\nfrom bci_mcp.visualization import SignalViewer\n\n# Connect to an OpenBCI Cyton board\ndevice = OpenBciDevice(port=\"/dev/ttyUSB0\", board_type=\"cyton\")\ndevice.connect()\n\n# Start data streaming\ndevice.start_stream()\n\n# Create a real-time signal viewer\nviewer = SignalViewer(device)\nviewer.show()\n\n# Add an event marker\ndevice.add_marker(code=1, description=\"Stimulus onset\")\n\n# Access raw data\ndata = device.get_data(seconds=10)\n\n# Stop streaming when done\ndevice.stop_stream()\ndevice.disconnect()\n</code></pre>"},{"location":"features/bci-features/#next-steps","title":"Next Steps","text":"<p>To understand how these BCI features integrate with the Model Context Protocol, see the MCP Integration documentation.</p>"},{"location":"features/mcp-integration/","title":"MCP Integration","text":"<p>This document explains how the Brain-Computer Interface (BCI) integrates with the Model Context Protocol (MCP) in the BCI-MCP system.</p>"},{"location":"features/mcp-integration/#overview","title":"Overview","text":"<p>The Model Context Protocol (MCP) allows large language models (LLMs) to receive and process brain activity data as additional context. This integration enables AI systems to respond to and adapt based on neural signals, creating a more intuitive human-AI interaction.</p>"},{"location":"features/mcp-integration/#key-integration-points","title":"Key Integration Points","text":""},{"location":"features/mcp-integration/#data-flow-from-bci-to-mcp","title":"Data Flow from BCI to MCP","text":"<pre><code>BCI Device \u2192 Signal Processing \u2192 Feature Extraction \u2192 Context Formatting \u2192 MCP API \u2192 Language Model\n</code></pre> <ol> <li>BCI Device: Acquires raw neural signals</li> <li>Signal Processing: Filters and cleans the signals</li> <li>Feature Extraction: Extracts meaningful features from processed data</li> <li>Context Formatting: Converts features into MCP-compatible format</li> <li>MCP API: Receives the formatted context</li> <li>Language Model: Uses the context for enhanced responses</li> </ol>"},{"location":"features/mcp-integration/#context-data-format","title":"Context Data Format","text":"<p>BCI data is structured into the MCP context format as follows:</p> <pre><code>{\n  \"bci_data\": {\n    \"metadata\": {\n      \"device_type\": \"openBCI\",\n      \"channels\": 8,\n      \"sampling_rate\": 250,\n      \"timestamp\": 1679569835.245\n    },\n    \"features\": {\n      \"band_powers\": {\n        \"alpha\": [0.75, 0.65, 0.82, 0.71, 0.68, 0.72, 0.69, 0.77],\n        \"beta\": [0.45, 0.52, 0.48, 0.51, 0.47, 0.49, 0.50, 0.46],\n        \"theta\": [0.62, 0.58, 0.63, 0.59, 0.61, 0.60, 0.57, 0.64],\n        \"delta\": [0.85, 0.88, 0.83, 0.87, 0.86, 0.84, 0.89, 0.82]\n      },\n      \"connectivity\": {\n        \"coherence\": [[0.8, 0.5, 0.3], [0.5, 0.7, 0.4], [0.3, 0.4, 0.9]]\n      },\n      \"statistics\": {\n        \"mean\": [0.12, 0.15, 0.11, 0.14, 0.13, 0.12, 0.16, 0.11],\n        \"variance\": [0.05, 0.06, 0.04, 0.05, 0.05, 0.04, 0.06, 0.04]\n      },\n      \"events\": [\n        {\"type\": \"blink\", \"timestamp\": 1679569835.125, \"confidence\": 0.92},\n        {\"type\": \"attention_spike\", \"timestamp\": 1679569836.352, \"confidence\": 0.87}\n      ]\n    },\n    \"cognitive_state\": {\n      \"attention\": 0.75,\n      \"relaxation\": 0.62,\n      \"cognitive_load\": 0.45,\n      \"arousal\": 0.58\n    }\n  }\n}\n</code></pre>"},{"location":"features/mcp-integration/#feature-extraction","title":"Feature Extraction","text":"<p>The BCI-MCP system extracts various features from neural signals for use with MCP:</p>"},{"location":"features/mcp-integration/#spectral-features","title":"Spectral Features","text":"<ul> <li>Band Powers: Power in different frequency bands (alpha, beta, theta, delta, gamma)</li> <li>Spectral Entropy: Measure of unpredictability in the frequency domain</li> <li>Peak Frequencies: Dominant frequencies in the signal</li> </ul>"},{"location":"features/mcp-integration/#temporal-features","title":"Temporal Features","text":"<ul> <li>Event-Related Potentials: Neural responses to specific events</li> <li>Statistical Measures: Mean, variance, skewness, kurtosis</li> <li>Signal Complexity: Measures like Hjorth parameters and sample entropy</li> </ul>"},{"location":"features/mcp-integration/#spatial-features","title":"Spatial Features","text":"<ul> <li>Spatial Filters: Common Spatial Patterns (CSP) and similar techniques</li> <li>Connectivity Measures: Coherence, phase synchrony between channels</li> <li>Source Localization: Estimates of neural source activity</li> </ul>"},{"location":"features/mcp-integration/#cognitive-state-estimation","title":"Cognitive State Estimation","text":"<p>The system estimates cognitive states from BCI data for enhanced interaction:</p> <ul> <li>Attention Level: Focus and engagement</li> <li>Cognitive Load: Mental workload</li> <li>Emotional State: Valence and arousal</li> <li>Relaxation: Calm and meditative states</li> </ul>"},{"location":"features/mcp-integration/#integration-methods","title":"Integration Methods","text":""},{"location":"features/mcp-integration/#direct-api-integration","title":"Direct API Integration","text":"<pre><code>from bci_mcp.devices import OpenBciDevice\nfrom bci_mcp.processing import FeatureExtractor\nfrom bci_mcp.mcp import McpClient\n\n# Initialize BCI device\ndevice = OpenBciDevice(port=\"/dev/ttyUSB0\")\ndevice.connect()\ndevice.start_stream()\n\n# Extract features from BCI data\nextractor = FeatureExtractor()\nbci_data = device.get_data(seconds=5)\nfeatures = extractor.process(bci_data)\n\n# Create MCP client and send query with BCI context\nclient = McpClient(api_key=\"your_api_key\")\nresponse = client.query(\n    prompt=\"How should I modify my meditation practice based on my current state?\",\n    context={\"bci_data\": features}\n)\n\nprint(response.text)\n\n# Clean up\ndevice.stop_stream()\ndevice.disconnect()\n</code></pre>"},{"location":"features/mcp-integration/#streaming-integration","title":"Streaming Integration","text":"<p>For real-time applications, BCI-MCP supports streaming integration:</p> <pre><code>from bci_mcp.devices import OpenBciDevice\nfrom bci_mcp.processing import StreamProcessor\nfrom bci_mcp.mcp import McpClient\n\n# Initialize components\ndevice = OpenBciDevice(port=\"/dev/ttyUSB0\")\nprocessor = StreamProcessor()\nclient = McpClient(api_key=\"your_api_key\")\n\n# Configure streaming callback\ndef on_features_extracted(features):\n    response = client.query(\n        prompt=\"Adapt to my current cognitive state\",\n        context={\"bci_data\": features}\n    )\n    print(response.text)\n\n# Start streaming with processing\ndevice.connect()\nprocessor.set_callback(on_features_extracted)\nprocessor.process_stream(device)\n\n# Run for 60 seconds then clean up\nimport time\ntime.sleep(60)\nprocessor.stop()\ndevice.disconnect()\n</code></pre>"},{"location":"features/mcp-integration/#applications","title":"Applications","text":""},{"location":"features/mcp-integration/#adaptive-interfaces","title":"Adaptive Interfaces","text":"<p>BCI-MCP enables interfaces that adapt to the user's cognitive state:</p> <ul> <li>Adjusting complexity based on cognitive load</li> <li>Providing more assistance when attention decreases</li> <li>Adapting information presentation based on emotional state</li> </ul>"},{"location":"features/mcp-integration/#neuro-augmented-ai","title":"Neuro-Augmented AI","text":"<p>Combining neural data with AI capabilities:</p> <ul> <li>Enhanced creative processes using neural feedback</li> <li>Personalized learning systems that adapt to cognitive state</li> <li>Meditation and mindfulness applications with neural guidance</li> </ul>"},{"location":"features/mcp-integration/#assistive-technology","title":"Assistive Technology","text":"<p>BCI-MCP provides powerful assistive capabilities:</p> <ul> <li>Communication systems for individuals with motor disabilities</li> <li>Cognitive assistance that adapts to the user's needs</li> <li>Emotional support systems with neural monitoring</li> </ul>"},{"location":"features/mcp-integration/#best-practices","title":"Best Practices","text":""},{"location":"features/mcp-integration/#privacy-and-security","title":"Privacy and Security","text":"<p>When integrating BCI with MCP, consider these privacy practices:</p> <ul> <li>Implement data minimization by only sending necessary features</li> <li>Use secure, encrypted connections for all data transmission</li> <li>Provide clear user control over when and what data is sent</li> <li>Consider local processing when possible</li> </ul>"},{"location":"features/mcp-integration/#performance-optimization","title":"Performance Optimization","text":"<p>For optimal performance:</p> <ul> <li>Balance feature richness with transmission efficiency</li> <li>Implement caching for frequently used context</li> <li>Use incremental updates for streaming applications</li> <li>Monitor latency and adjust processing accordingly</li> </ul>"},{"location":"features/mcp-integration/#next-steps","title":"Next Steps","text":"<p>For more detailed information on signal processing techniques, see the Advanced Signal Processing documentation.</p>"},{"location":"features/signal-processing/","title":"Advanced Signal Processing","text":"<p>This document describes the advanced signal processing capabilities of the BCI-MCP system.</p>"},{"location":"features/signal-processing/#overview","title":"Overview","text":"<p>The BCI-MCP system includes powerful signal processing capabilities designed to extract meaningful features from brain activity data. These processing techniques are essential for converting raw EEG signals into usable input for the Model Context Protocol (MCP).</p>"},{"location":"features/signal-processing/#signal-preprocessing","title":"Signal Preprocessing","text":""},{"location":"features/signal-processing/#filtering","title":"Filtering","text":"<p>The system supports multiple types of filters to clean raw EEG signals:</p> <ul> <li>Bandpass Filtering: Isolates specific frequency bands (e.g., alpha, beta, theta, delta)</li> <li>Notch Filtering: Removes power line interference (50Hz or 60Hz)</li> <li>Spatial Filtering: Enhances signal-to-noise ratio and separates sources</li> <li>Adaptive Filtering: Dynamically adjusts to changing signal conditions</li> </ul> <p>Example implementation:</p> <pre><code>from src.signal_processing import filters\n\n# Apply bandpass filter to isolate alpha waves (8-13 Hz)\nfiltered_signal = filters.bandpass(raw_signal, low_cutoff=8, high_cutoff=13, sampling_rate=250)\n\n# Apply notch filter to remove 60Hz power line interference\nclean_signal = filters.notch(filtered_signal, notch_freq=60, sampling_rate=250)\n</code></pre>"},{"location":"features/signal-processing/#artifact-removal","title":"Artifact Removal","text":"<p>The system includes methods for removing common artifacts:</p> <ul> <li>Independent Component Analysis (ICA): Separates brain activity from artifacts</li> <li>Wavelet Denoising: Removes transient noise while preserving signal features</li> <li>Threshold-based Rejection: Removes segments with extreme values</li> </ul>"},{"location":"features/signal-processing/#feature-extraction","title":"Feature Extraction","text":""},{"location":"features/signal-processing/#time-domain-features","title":"Time Domain Features","text":"<ul> <li>Event-Related Potentials (ERPs): Neural responses time-locked to specific events</li> <li>Statistical Measures: Mean, variance, skewness, kurtosis</li> <li>Hjorth Parameters: Activity, mobility, complexity</li> </ul>"},{"location":"features/signal-processing/#frequency-domain-features","title":"Frequency Domain Features","text":"<ul> <li>Power Spectral Density (PSD): Distribution of signal power across frequencies</li> <li>Spectral Band Power: Power in specific frequency bands (delta, theta, alpha, beta, gamma)</li> <li>Spectral Entropy: Measure of spectral complexity</li> </ul>"},{"location":"features/signal-processing/#time-frequency-analysis","title":"Time-Frequency Analysis","text":"<ul> <li>Short-Time Fourier Transform (STFT): For time-varying spectral analysis</li> <li>Wavelet Transform: Multi-resolution analysis for transient events</li> <li>Empirical Mode Decomposition: Adaptive decomposition for non-stationary signals</li> </ul>"},{"location":"features/signal-processing/#machine-learning-integration","title":"Machine Learning Integration","text":"<p>The signal processing pipeline can be integrated with various machine learning approaches:</p> <ul> <li>Feature Selection: Automatic selection of most discriminative features</li> <li>Classification Algorithms: SVM, Random Forests, Neural Networks</li> <li>Deep Learning: Convolutional and recurrent networks for end-to-end processing</li> </ul>"},{"location":"features/signal-processing/#performance-optimization","title":"Performance Optimization","text":"<p>The system is optimized for real-time processing with:</p> <ul> <li>GPU Acceleration: For computationally intensive operations</li> <li>Parallel Processing: For multi-channel data</li> <li>Adaptive Processing: Automatically adjusts parameters based on signal quality</li> </ul>"},{"location":"features/signal-processing/#usage-examples","title":"Usage Examples","text":"<pre><code>from src.signal_processing import pipeline\n\n# Create a processing pipeline\nproc_pipeline = pipeline.Pipeline([\n    pipeline.Bandpass(low_cutoff=1, high_cutoff=50),\n    pipeline.Notch(notch_freq=60),\n    pipeline.ICA(components=8),\n    pipeline.FeatureExtractor(['psd', 'band_power', 'hjorth'])\n])\n\n# Apply the pipeline to raw EEG data\nfeatures = proc_pipeline.process(raw_eeg_data)\n</code></pre>"},{"location":"features/signal-processing/#next-steps","title":"Next Steps","text":"<p>After understanding the signal processing capabilities, learn about MCP Integration to see how these processed signals are used by the Model Context Protocol. </p>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>This guide explains how to configure the BCI-MCP system for your specific needs.</p>"},{"location":"getting-started/configuration/#configuration-files","title":"Configuration Files","text":"<p>BCI-MCP uses several configuration files:</p> <ul> <li><code>config.yaml</code>: Main configuration file for the system</li> <li><code>.env</code>: Environment variables for Docker and sensitive settings</li> <li><code>mkdocs.yml</code>: Documentation site configuration</li> </ul>"},{"location":"getting-started/configuration/#basic-configuration","title":"Basic Configuration","text":""},{"location":"getting-started/configuration/#configyaml","title":"config.yaml","text":"<p>The main configuration file supports the following settings:</p> <pre><code># Basic settings\napplication:\n  name: \"BCI-MCP\"\n  version: \"1.0.0\"\n  log_level: \"INFO\"  # DEBUG, INFO, WARNING, ERROR, CRITICAL\n\n# BCI device configuration\nbci:\n  device_type: \"openBCI\"  # openBCI, emotiv, neurosky, etc.\n  sampling_rate: 250  # Hz\n  channels: 8  # Number of EEG channels\n  port: \"/dev/ttyUSB0\"  # Serial port or device path\n\n# MCP settings\nmcp:\n  api_endpoint: \"https://api.example.com/mcp\"\n  api_key: \"${MCP_API_KEY}\"  # Loaded from .env file\n  model: \"default\"\n  timeout: 30  # seconds\n</code></pre>"},{"location":"getting-started/configuration/#environment-variables-env","title":"Environment Variables (.env)","text":"<p>Create a <code>.env</code> file in the root directory with your sensitive configuration:</p> <pre><code>MCP_API_KEY=your_api_key_here\nDATABASE_URL=postgresql://user:password@localhost/bci_mcp\n</code></pre>"},{"location":"getting-started/configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"getting-started/configuration/#signal-processing","title":"Signal Processing","text":"<p>Configure signal processing in the <code>config.yaml</code> file:</p> <pre><code>signal_processing:\n  filters:\n    - type: \"bandpass\"\n      low_cutoff: 1  # Hz\n      high_cutoff: 50  # Hz\n    - type: \"notch\"\n      frequency: 60  # Hz\n\n  features:\n    - type: \"power_spectral_density\"\n      enabled: true\n    - type: \"time_domain\"\n      enabled: true\n</code></pre>"},{"location":"getting-started/configuration/#model-context-protocol-mcp","title":"Model Context Protocol (MCP)","text":"<p>Configure MCP settings for advanced usage:</p> <pre><code>mcp_advanced:\n  context_window: 5000  # tokens\n  temperature: 0.7\n  max_tokens: 2000\n  stream_response: true\n</code></pre>"},{"location":"getting-started/configuration/#configuration-validation","title":"Configuration Validation","text":"<p>To validate your configuration:</p> <pre><code>python src/utils/validate_config.py\n</code></pre> <p>This will check your configuration files for errors and provide recommendations.</p>"},{"location":"getting-started/configuration/#next-steps","title":"Next Steps","text":"<p>After configuring your BCI-MCP system, proceed to BCI Features to learn about the available features. </p>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide will help you set up the BCI-MCP system on your machine.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing the BCI-MCP system, ensure you have the following prerequisites:</p> <ul> <li>Python 3.8 or higher</li> <li>Git</li> <li>Docker and Docker Compose (for containerized deployment)</li> <li>4GB RAM minimum (8GB recommended)</li> </ul>"},{"location":"getting-started/installation/#installation-methods","title":"Installation Methods","text":"<p>You can install BCI-MCP using one of the following methods:</p>"},{"location":"getting-started/installation/#method-1-direct-installation","title":"Method 1: Direct Installation","text":"<ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/enkhbold470/bci-mcp.git\ncd bci-mcp\n</code></pre></p> </li> <li> <p>Create and activate a virtual environment:    <pre><code>python -m venv venv\n# On Windows\nvenv\\Scripts\\activate\n# On macOS/Linux\nsource venv/bin/activate\n</code></pre></p> </li> <li> <p>Install the required dependencies:    <pre><code>pip install -r requirements.txt\n</code></pre></p> </li> </ol>"},{"location":"getting-started/installation/#method-2-docker-installation","title":"Method 2: Docker Installation","text":"<ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/enkhbold470/bci-mcp.git\ncd bci-mcp\n</code></pre></p> </li> <li> <p>Build and run the Docker containers:    <pre><code>docker-compose up -d\n</code></pre></p> </li> </ol>"},{"location":"getting-started/installation/#verifying-installation","title":"Verifying Installation","text":"<p>To verify that the installation was successful:</p> <ol> <li> <p>Run the built-in test script:    <pre><code>python src/test_installation.py\n</code></pre></p> </li> <li> <p>Check for the success message indicating that all components are installed correctly.</p> </li> </ol>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>After successfully installing BCI-MCP, proceed to the Quick Start guide to begin using the system. </p>"},{"location":"getting-started/quick-start/","title":"Quick Start Guide","text":"<p>This guide will help you get started with BCI-MCP quickly. We'll walk through installation, basic configuration, and running your first BCI session with MCP integration.</p>"},{"location":"getting-started/quick-start/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have:</p> <ul> <li>Python 3.10 or newer</li> <li>Compatible EEG hardware (or use simulated mode for testing)</li> <li>Basic understanding of terminal/command line usage</li> </ul>"},{"location":"getting-started/quick-start/#installation","title":"Installation","text":""},{"location":"getting-started/quick-start/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/enkhbold470/bci-mcp.git\ncd bci-mcp\n</code></pre>"},{"location":"getting-started/quick-start/#2-create-a-virtual-environment","title":"2. Create a Virtual Environment","text":"<p>We recommend using a virtual environment to avoid conflicts with other Python packages:</p> <pre><code># Using venv\npython -m venv venv\n\n# Activate on Windows\nvenv\\Scripts\\activate\n\n# Activate on macOS/Linux\nsource venv/bin/activate\n</code></pre>"},{"location":"getting-started/quick-start/#3-install-dependencies","title":"3. Install Dependencies","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/quick-start/#basic-usage","title":"Basic Usage","text":""},{"location":"getting-started/quick-start/#running-in-interactive-mode","title":"Running in Interactive Mode","text":"<p>The simplest way to start is with the interactive console mode:</p> <pre><code>python src/main.py --interactive\n</code></pre> <p>This will display a menu-driven interface for: - Selecting your EEG device - Calibrating the system - Starting/stopping data streaming - Recording and analyzing sessions</p>"},{"location":"getting-started/quick-start/#list-available-eeg-devices","title":"List Available EEG Devices","text":"<p>To see which EEG devices are connected to your system:</p> <pre><code>python src/main.py --list-ports\n</code></pre> <p>The output will show available serial ports and connected devices.</p>"},{"location":"getting-started/quick-start/#recording-a-bci-session","title":"Recording a BCI Session","text":"<p>To record a 60-second BCI session:</p> <pre><code>python src/main.py --port /dev/tty.usbmodem1101 --record 60\n</code></pre> <p>Replace <code>/dev/tty.usbmodem1101</code> with your device's port as shown in the <code>--list-ports</code> output.</p>"},{"location":"getting-started/quick-start/#calibration","title":"Calibration","text":"<p>For optimal performance, calibrate the system before a session:</p> <pre><code>python src/main.py --port /dev/tty.usbmodem1101 --calibrate\n</code></pre>"},{"location":"getting-started/quick-start/#starting-the-mcp-server","title":"Starting the MCP Server","text":"<p>To expose your BCI functionality through the Model Context Protocol:</p> <pre><code>python src/main.py --server\n</code></pre> <p>By default, this starts an MCP server on <code>ws://localhost:8765</code>.</p>"},{"location":"getting-started/quick-start/#connecting-to-the-mcp-server","title":"Connecting to the MCP Server","text":""},{"location":"getting-started/quick-start/#using-python","title":"Using Python","text":"<p>Here's a simple example of connecting to the MCP server using Python:</p> <pre><code>import asyncio\nimport json\nfrom websockets import connect\n\nasync def use_bci_mcp():\n    async with connect(\"ws://localhost:8765\") as websocket:\n        # Get capabilities\n        await websocket.send(json.dumps({\n            \"jsonrpc\": \"2.0\",\n            \"method\": \"get_capabilities\",\n            \"id\": 1\n        }))\n        response = await websocket.recv()\n        print(f\"Capabilities: {json.loads(response)}\")\n\n        # Connect to a device\n        await websocket.send(json.dumps({\n            \"jsonrpc\": \"2.0\",\n            \"method\": \"invoke_tool_connect_device\",\n            \"params\": {\"port\": \"/dev/tty.usbmodem1101\"},\n            \"id\": 2\n        }))\n        response = await websocket.recv()\n        print(f\"Connection result: {json.loads(response)}\")\n\n        # Start streaming\n        await websocket.send(json.dumps({\n            \"jsonrpc\": \"2.0\",\n            \"method\": \"invoke_tool_start_stream\",\n            \"id\": 3\n        }))\n        response = await websocket.recv()\n        print(f\"Streaming result: {json.loads(response)}\")\n\n        # Read brain signals\n        for _ in range(5):  # Get 5 samples\n            await websocket.send(json.dumps({\n                \"jsonrpc\": \"2.0\",\n                \"method\": \"get_resource_brain_signals\",\n                \"id\": 4\n            }))\n            response = await websocket.recv()\n            print(f\"Brain signals: {json.loads(response)}\")\n            await asyncio.sleep(1)\n\n        # Stop streaming\n        await websocket.send(json.dumps({\n            \"jsonrpc\": \"2.0\",\n            \"method\": \"invoke_tool_stop_stream\",\n            \"id\": 5\n        }))\n        response = await websocket.recv()\n        print(f\"Stop result: {json.loads(response)}\")\n\nasyncio.run(use_bci_mcp())\n</code></pre>"},{"location":"getting-started/quick-start/#using-other-languages","title":"Using Other Languages","text":"<p>The MCP protocol uses standard WebSockets and JSON-RPC 2.0, so you can connect using any language that supports these technologies. See the MCP specification for detailed protocol information.</p>"},{"location":"getting-started/quick-start/#common-operations","title":"Common Operations","text":"<p>Here are some common operations you might want to perform:</p>"},{"location":"getting-started/quick-start/#calibrate-the-device","title":"Calibrate the Device","text":"<pre><code>await websocket.send(json.dumps({\n    \"jsonrpc\": \"2.0\",\n    \"method\": \"invoke_tool_calibrate_device\",\n    \"params\": {\"duration\": 10},\n    \"id\": 10\n}))\n</code></pre>"},{"location":"getting-started/quick-start/#save-session-data","title":"Save Session Data","text":"<pre><code>await websocket.send(json.dumps({\n    \"jsonrpc\": \"2.0\",\n    \"method\": \"invoke_tool_save_data\",\n    \"params\": {\"format\": \"npz\"},\n    \"id\": 11\n}))\n</code></pre>"},{"location":"getting-started/quick-start/#get-session-information","title":"Get Session Information","text":"<pre><code>await websocket.send(json.dumps({\n    \"jsonrpc\": \"2.0\",\n    \"method\": \"get_resource_session_info\",\n    \"id\": 12\n}))\n</code></pre>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<p>Now that you have BCI-MCP up and running, you might want to:</p> <ol> <li>Learn about advanced BCI features</li> <li>Explore the MCP integration in more detail</li> <li>Check the API reference for programmatic usage</li> </ol> <p>If you encounter any issues, please check the troubleshooting section or submit an issue on our GitHub repository.</p>"}]}